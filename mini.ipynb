{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mini.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPf3GfpZ6q7Dvd/2BAxnTtC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raviteja1432/AI/blob/main/mini.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Tg5x3fDzCcP",
        "outputId": "a2a54103-f255-436c-dbfc-bec551e0b5ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "giW__S4vsjXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/livercancer1.csv')\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "K9i8dIy_10Z9",
        "outputId": "3b1b9d6a-b567-486f-f4e9-241ab1ac7254"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Age of the patient Gender of the patient  Total Bilirubin  \\\n",
              "0                    65.0                Female              0.7   \n",
              "1                    62.0                  Male             10.9   \n",
              "2                    62.0                  Male              7.3   \n",
              "3                    58.0                  Male              1.0   \n",
              "4                    72.0                  Male              3.9   \n",
              "...                   ...                   ...              ...   \n",
              "30686                50.0                  Male              2.2   \n",
              "30687                55.0                  Male              2.9   \n",
              "30688                54.0                  Male              6.8   \n",
              "30689                48.0                Female              1.9   \n",
              "30690                30.0                  Male              3.1   \n",
              "\n",
              "       Direct Bilirubin   Alkphos Alkaline Phosphotase  \\\n",
              "0                   0.1                          187.0   \n",
              "1                   5.5                          699.0   \n",
              "2                   4.1                          490.0   \n",
              "3                   0.4                          182.0   \n",
              "4                   2.0                          195.0   \n",
              "...                 ...                            ...   \n",
              "30686               1.0                          610.0   \n",
              "30687               1.3                          482.0   \n",
              "30688               3.0                          542.0   \n",
              "30689               1.0                          231.0   \n",
              "30690               1.6                          253.0   \n",
              "\n",
              "        Sgpt Alamine Aminotransferase  Sgot Aspartate Aminotransferase  \\\n",
              "0                                16.0                             18.0   \n",
              "1                                64.0                            100.0   \n",
              "2                                60.0                             68.0   \n",
              "3                                14.0                             20.0   \n",
              "4                                27.0                             59.0   \n",
              "...                               ...                              ...   \n",
              "30686                            17.0                             28.0   \n",
              "30687                            22.0                             34.0   \n",
              "30688                           116.0                             66.0   \n",
              "30689                            16.0                             55.0   \n",
              "30690                            80.0                            406.0   \n",
              "\n",
              "       Total Protiens   ALB Albumin  A/G Ratio Albumin and Globulin Ratio  \\\n",
              "0                 6.8           3.3                                  0.90   \n",
              "1                 7.5           3.2                                  0.74   \n",
              "2                 7.0           3.3                                  0.89   \n",
              "3                 6.8           3.4                                  1.00   \n",
              "4                 7.3           2.4                                  0.40   \n",
              "...               ...           ...                                   ...   \n",
              "30686             7.3           2.6                                  0.55   \n",
              "30687             7.0           2.4                                  0.50   \n",
              "30688             6.4           3.1                                  0.90   \n",
              "30689             4.3           1.6                                  0.60   \n",
              "30690             6.8           3.9                                  1.30   \n",
              "\n",
              "       Result  \n",
              "0           1  \n",
              "1           1  \n",
              "2           1  \n",
              "3           1  \n",
              "4           1  \n",
              "...       ...  \n",
              "30686       1  \n",
              "30687       1  \n",
              "30688       1  \n",
              "30689       1  \n",
              "30690       1  \n",
              "\n",
              "[30691 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-521a43b0-5329-4657-bcc5-37ef6a3aba0f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age of the patient</th>\n",
              "      <th>Gender of the patient</th>\n",
              "      <th>Total Bilirubin</th>\n",
              "      <th>Direct Bilirubin</th>\n",
              "      <th>Alkphos Alkaline Phosphotase</th>\n",
              "      <th>Sgpt Alamine Aminotransferase</th>\n",
              "      <th>Sgot Aspartate Aminotransferase</th>\n",
              "      <th>Total Protiens</th>\n",
              "      <th>ALB Albumin</th>\n",
              "      <th>A/G Ratio Albumin and Globulin Ratio</th>\n",
              "      <th>Result</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>65.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.1</td>\n",
              "      <td>187.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>6.8</td>\n",
              "      <td>3.3</td>\n",
              "      <td>0.90</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>62.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>10.9</td>\n",
              "      <td>5.5</td>\n",
              "      <td>699.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>7.5</td>\n",
              "      <td>3.2</td>\n",
              "      <td>0.74</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>62.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>7.3</td>\n",
              "      <td>4.1</td>\n",
              "      <td>490.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3.3</td>\n",
              "      <td>0.89</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>58.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>182.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>6.8</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>72.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>3.9</td>\n",
              "      <td>2.0</td>\n",
              "      <td>195.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>7.3</td>\n",
              "      <td>2.4</td>\n",
              "      <td>0.40</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30686</th>\n",
              "      <td>50.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>2.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>610.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>7.3</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.55</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30687</th>\n",
              "      <td>55.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>2.9</td>\n",
              "      <td>1.3</td>\n",
              "      <td>482.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2.4</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30688</th>\n",
              "      <td>54.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>6.8</td>\n",
              "      <td>3.0</td>\n",
              "      <td>542.0</td>\n",
              "      <td>116.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>6.4</td>\n",
              "      <td>3.1</td>\n",
              "      <td>0.90</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30689</th>\n",
              "      <td>48.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>1.9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>231.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>4.3</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.60</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30690</th>\n",
              "      <td>30.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.6</td>\n",
              "      <td>253.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>406.0</td>\n",
              "      <td>6.8</td>\n",
              "      <td>3.9</td>\n",
              "      <td>1.30</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30691 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-521a43b0-5329-4657-bcc5-37ef6a3aba0f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-521a43b0-5329-4657-bcc5-37ef6a3aba0f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-521a43b0-5329-4657-bcc5-37ef6a3aba0f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0I-_abR2ASz",
        "outputId": "d0efbefd-0c84-42c8-f7f2-6fb74f5b4231"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 30691 entries, 0 to 30690\n",
            "Data columns (total 11 columns):\n",
            " #   Column                                Non-Null Count  Dtype  \n",
            "---  ------                                --------------  -----  \n",
            " 0   Age of the patient                    30689 non-null  float64\n",
            " 1   Gender of the patient                 29789 non-null  object \n",
            " 2   Total Bilirubin                       30043 non-null  float64\n",
            " 3   Direct Bilirubin                      30130 non-null  float64\n",
            " 4    Alkphos Alkaline Phosphotase         29895 non-null  float64\n",
            " 5    Sgpt Alamine Aminotransferase        30153 non-null  float64\n",
            " 6   Sgot Aspartate Aminotransferase       30229 non-null  float64\n",
            " 7   Total Protiens                        30228 non-null  float64\n",
            " 8    ALB Albumin                          30197 non-null  float64\n",
            " 9   A/G Ratio Albumin and Globulin Ratio  30132 non-null  float64\n",
            " 10  Result                                30691 non-null  int64  \n",
            "dtypes: float64(9), int64(1), object(1)\n",
            "memory usage: 2.6+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbYy0kJI4ZEw",
        "outputId": "56537dcf-a81f-4a4f-e612-037b01247e84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Age of the patient                        2\n",
              "Gender of the patient                   902\n",
              "Total Bilirubin                         648\n",
              "Direct Bilirubin                        561\n",
              " Alkphos Alkaline Phosphotase           796\n",
              " Sgpt Alamine Aminotransferase          538\n",
              "Sgot Aspartate Aminotransferase         462\n",
              "Total Protiens                          463\n",
              " ALB Albumin                            494\n",
              "A/G Ratio Albumin and Globulin Ratio    559\n",
              "Result                                    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=data.drop(['Gender of the patient'],axis=1)"
      ],
      "metadata": {
        "id": "iG5ZYjwewTBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def binary_encode(df, column, positive_value):\n",
        "    df = df.copy()\n",
        "    df[column] = df[column].apply(lambda x: 1 if x == positive_value else 0)\n",
        "    return df"
      ],
      "metadata": {
        "id": "gExLD7SNFPpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = binary_encode(data, 'Result',2)"
      ],
      "metadata": {
        "id": "DSTUoQsoGine"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "siNpePWGGtsR",
        "outputId": "5e7ad58d-91c5-4e2e-9489-c3f6e3cc7aee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Age of the patient  Total Bilirubin  Direct Bilirubin  \\\n",
              "0                    65.0              0.7               0.1   \n",
              "1                    62.0             10.9               5.5   \n",
              "2                    62.0              7.3               4.1   \n",
              "3                    58.0              1.0               0.4   \n",
              "4                    72.0              3.9               2.0   \n",
              "...                   ...              ...               ...   \n",
              "30686                50.0              2.2               1.0   \n",
              "30687                55.0              2.9               1.3   \n",
              "30688                54.0              6.8               3.0   \n",
              "30689                48.0              1.9               1.0   \n",
              "30690                30.0              3.1               1.6   \n",
              "\n",
              "        Alkphos Alkaline Phosphotase   Sgpt Alamine Aminotransferase  \\\n",
              "0                              187.0                            16.0   \n",
              "1                              699.0                            64.0   \n",
              "2                              490.0                            60.0   \n",
              "3                              182.0                            14.0   \n",
              "4                              195.0                            27.0   \n",
              "...                              ...                             ...   \n",
              "30686                          610.0                            17.0   \n",
              "30687                          482.0                            22.0   \n",
              "30688                          542.0                           116.0   \n",
              "30689                          231.0                            16.0   \n",
              "30690                          253.0                            80.0   \n",
              "\n",
              "       Sgot Aspartate Aminotransferase  Total Protiens   ALB Albumin  \\\n",
              "0                                 18.0             6.8           3.3   \n",
              "1                                100.0             7.5           3.2   \n",
              "2                                 68.0             7.0           3.3   \n",
              "3                                 20.0             6.8           3.4   \n",
              "4                                 59.0             7.3           2.4   \n",
              "...                                ...             ...           ...   \n",
              "30686                             28.0             7.3           2.6   \n",
              "30687                             34.0             7.0           2.4   \n",
              "30688                             66.0             6.4           3.1   \n",
              "30689                             55.0             4.3           1.6   \n",
              "30690                            406.0             6.8           3.9   \n",
              "\n",
              "       A/G Ratio Albumin and Globulin Ratio  Result  \n",
              "0                                      0.90       0  \n",
              "1                                      0.74       0  \n",
              "2                                      0.89       0  \n",
              "3                                      1.00       0  \n",
              "4                                      0.40       0  \n",
              "...                                     ...     ...  \n",
              "30686                                  0.55       0  \n",
              "30687                                  0.50       0  \n",
              "30688                                  0.90       0  \n",
              "30689                                  0.60       0  \n",
              "30690                                  1.30       0  \n",
              "\n",
              "[30691 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dee65a84-3d59-47c9-a873-79bc95de63e2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age of the patient</th>\n",
              "      <th>Total Bilirubin</th>\n",
              "      <th>Direct Bilirubin</th>\n",
              "      <th>Alkphos Alkaline Phosphotase</th>\n",
              "      <th>Sgpt Alamine Aminotransferase</th>\n",
              "      <th>Sgot Aspartate Aminotransferase</th>\n",
              "      <th>Total Protiens</th>\n",
              "      <th>ALB Albumin</th>\n",
              "      <th>A/G Ratio Albumin and Globulin Ratio</th>\n",
              "      <th>Result</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>65.0</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.1</td>\n",
              "      <td>187.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>6.8</td>\n",
              "      <td>3.3</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>62.0</td>\n",
              "      <td>10.9</td>\n",
              "      <td>5.5</td>\n",
              "      <td>699.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>7.5</td>\n",
              "      <td>3.2</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>62.0</td>\n",
              "      <td>7.3</td>\n",
              "      <td>4.1</td>\n",
              "      <td>490.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3.3</td>\n",
              "      <td>0.89</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>58.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>182.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>6.8</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>72.0</td>\n",
              "      <td>3.9</td>\n",
              "      <td>2.0</td>\n",
              "      <td>195.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>7.3</td>\n",
              "      <td>2.4</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30686</th>\n",
              "      <td>50.0</td>\n",
              "      <td>2.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>610.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>7.3</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30687</th>\n",
              "      <td>55.0</td>\n",
              "      <td>2.9</td>\n",
              "      <td>1.3</td>\n",
              "      <td>482.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2.4</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30688</th>\n",
              "      <td>54.0</td>\n",
              "      <td>6.8</td>\n",
              "      <td>3.0</td>\n",
              "      <td>542.0</td>\n",
              "      <td>116.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>6.4</td>\n",
              "      <td>3.1</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30689</th>\n",
              "      <td>48.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>231.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>4.3</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30690</th>\n",
              "      <td>30.0</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.6</td>\n",
              "      <td>253.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>406.0</td>\n",
              "      <td>6.8</td>\n",
              "      <td>3.9</td>\n",
              "      <td>1.30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30691 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dee65a84-3d59-47c9-a873-79bc95de63e2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dee65a84-3d59-47c9-a873-79bc95de63e2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dee65a84-3d59-47c9-a873-79bc95de63e2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data1=data"
      ],
      "metadata": {
        "id": "eBhLG74KKdG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y=data['Result']\n",
        "data=data.drop(['Result'],axis=1)"
      ],
      "metadata": {
        "id": "6omDKplyz6XA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "x=data.value_counts\n",
        "scale=preprocessing.MinMaxScaler()\n",
        "x_scaled=scale.fit_transform(data)\n",
        "df=pd.DataFrame(x_scaled)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "6Hw1Sh5byTnd",
        "outputId": "de4e7a89-180f-441e-e371-ebc0eb32028b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              0         1         2         3         4         5         6  \\\n",
              "0      0.709302  0.004021  0.000000  0.060576  0.003015  0.001626  0.594203   \n",
              "1      0.674419  0.140751  0.275510  0.310699  0.027136  0.018296  0.695652   \n",
              "2      0.674419  0.092493  0.204082  0.208598  0.025126  0.011791  0.623188   \n",
              "3      0.627907  0.008043  0.015306  0.058134  0.002010  0.002033  0.594203   \n",
              "4      0.790698  0.046917  0.096939  0.064485  0.008543  0.009961  0.666667   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "30686  0.534884  0.024129  0.045918  0.267220  0.003518  0.003659  0.666667   \n",
              "30687  0.593023  0.033512  0.061224  0.204690  0.006030  0.004879  0.623188   \n",
              "30688  0.581395  0.085791  0.147959  0.234001  0.053266  0.011384  0.536232   \n",
              "30689  0.511628  0.020107  0.045918  0.082071  0.003015  0.009148  0.231884   \n",
              "30690  0.302326  0.036193  0.076531  0.092819  0.035176  0.080504  0.594203   \n",
              "\n",
              "              7      8  \n",
              "0      0.521739  0.240  \n",
              "1      0.500000  0.176  \n",
              "2      0.521739  0.236  \n",
              "3      0.543478  0.280  \n",
              "4      0.326087  0.040  \n",
              "...         ...    ...  \n",
              "30686  0.369565  0.100  \n",
              "30687  0.326087  0.080  \n",
              "30688  0.478261  0.240  \n",
              "30689  0.152174  0.120  \n",
              "30690  0.652174  0.400  \n",
              "\n",
              "[30691 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3314a867-0531-46f5-982d-3c0c5f62c4a3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.709302</td>\n",
              "      <td>0.004021</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.060576</td>\n",
              "      <td>0.003015</td>\n",
              "      <td>0.001626</td>\n",
              "      <td>0.594203</td>\n",
              "      <td>0.521739</td>\n",
              "      <td>0.240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.674419</td>\n",
              "      <td>0.140751</td>\n",
              "      <td>0.275510</td>\n",
              "      <td>0.310699</td>\n",
              "      <td>0.027136</td>\n",
              "      <td>0.018296</td>\n",
              "      <td>0.695652</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.674419</td>\n",
              "      <td>0.092493</td>\n",
              "      <td>0.204082</td>\n",
              "      <td>0.208598</td>\n",
              "      <td>0.025126</td>\n",
              "      <td>0.011791</td>\n",
              "      <td>0.623188</td>\n",
              "      <td>0.521739</td>\n",
              "      <td>0.236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.627907</td>\n",
              "      <td>0.008043</td>\n",
              "      <td>0.015306</td>\n",
              "      <td>0.058134</td>\n",
              "      <td>0.002010</td>\n",
              "      <td>0.002033</td>\n",
              "      <td>0.594203</td>\n",
              "      <td>0.543478</td>\n",
              "      <td>0.280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.046917</td>\n",
              "      <td>0.096939</td>\n",
              "      <td>0.064485</td>\n",
              "      <td>0.008543</td>\n",
              "      <td>0.009961</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.326087</td>\n",
              "      <td>0.040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30686</th>\n",
              "      <td>0.534884</td>\n",
              "      <td>0.024129</td>\n",
              "      <td>0.045918</td>\n",
              "      <td>0.267220</td>\n",
              "      <td>0.003518</td>\n",
              "      <td>0.003659</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.369565</td>\n",
              "      <td>0.100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30687</th>\n",
              "      <td>0.593023</td>\n",
              "      <td>0.033512</td>\n",
              "      <td>0.061224</td>\n",
              "      <td>0.204690</td>\n",
              "      <td>0.006030</td>\n",
              "      <td>0.004879</td>\n",
              "      <td>0.623188</td>\n",
              "      <td>0.326087</td>\n",
              "      <td>0.080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30688</th>\n",
              "      <td>0.581395</td>\n",
              "      <td>0.085791</td>\n",
              "      <td>0.147959</td>\n",
              "      <td>0.234001</td>\n",
              "      <td>0.053266</td>\n",
              "      <td>0.011384</td>\n",
              "      <td>0.536232</td>\n",
              "      <td>0.478261</td>\n",
              "      <td>0.240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30689</th>\n",
              "      <td>0.511628</td>\n",
              "      <td>0.020107</td>\n",
              "      <td>0.045918</td>\n",
              "      <td>0.082071</td>\n",
              "      <td>0.003015</td>\n",
              "      <td>0.009148</td>\n",
              "      <td>0.231884</td>\n",
              "      <td>0.152174</td>\n",
              "      <td>0.120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30690</th>\n",
              "      <td>0.302326</td>\n",
              "      <td>0.036193</td>\n",
              "      <td>0.076531</td>\n",
              "      <td>0.092819</td>\n",
              "      <td>0.035176</td>\n",
              "      <td>0.080504</td>\n",
              "      <td>0.594203</td>\n",
              "      <td>0.652174</td>\n",
              "      <td>0.400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30691 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3314a867-0531-46f5-982d-3c0c5f62c4a3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3314a867-0531-46f5-982d-3c0c5f62c4a3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3314a867-0531-46f5-982d-3c0c5f62c4a3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.fillna(df.mean(),inplace=True)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "X-e1SOAIzX_V",
        "outputId": "023a4020-9e5e-4dc2-ad30-b53c41eee1ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              0         1         2         3         4         5         6  \\\n",
              "0      0.709302  0.004021  0.000000  0.060576  0.003015  0.001626  0.594203   \n",
              "1      0.674419  0.140751  0.275510  0.310699  0.027136  0.018296  0.695652   \n",
              "2      0.674419  0.092493  0.204082  0.208598  0.025126  0.011791  0.623188   \n",
              "3      0.627907  0.008043  0.015306  0.058134  0.002010  0.002033  0.594203   \n",
              "4      0.790698  0.046917  0.096939  0.064485  0.008543  0.009961  0.666667   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "30686  0.534884  0.024129  0.045918  0.267220  0.003518  0.003659  0.666667   \n",
              "30687  0.593023  0.033512  0.061224  0.204690  0.006030  0.004879  0.623188   \n",
              "30688  0.581395  0.085791  0.147959  0.234001  0.053266  0.011384  0.536232   \n",
              "30689  0.511628  0.020107  0.045918  0.082071  0.003015  0.009148  0.231884   \n",
              "30690  0.302326  0.036193  0.076531  0.092819  0.035176  0.080504  0.594203   \n",
              "\n",
              "              7      8  \n",
              "0      0.521739  0.240  \n",
              "1      0.500000  0.176  \n",
              "2      0.521739  0.236  \n",
              "3      0.543478  0.280  \n",
              "4      0.326087  0.040  \n",
              "...         ...    ...  \n",
              "30686  0.369565  0.100  \n",
              "30687  0.326087  0.080  \n",
              "30688  0.478261  0.240  \n",
              "30689  0.152174  0.120  \n",
              "30690  0.652174  0.400  \n",
              "\n",
              "[30691 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8e531de5-c9d8-455b-a3b2-96edcd6d9614\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.709302</td>\n",
              "      <td>0.004021</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.060576</td>\n",
              "      <td>0.003015</td>\n",
              "      <td>0.001626</td>\n",
              "      <td>0.594203</td>\n",
              "      <td>0.521739</td>\n",
              "      <td>0.240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.674419</td>\n",
              "      <td>0.140751</td>\n",
              "      <td>0.275510</td>\n",
              "      <td>0.310699</td>\n",
              "      <td>0.027136</td>\n",
              "      <td>0.018296</td>\n",
              "      <td>0.695652</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.674419</td>\n",
              "      <td>0.092493</td>\n",
              "      <td>0.204082</td>\n",
              "      <td>0.208598</td>\n",
              "      <td>0.025126</td>\n",
              "      <td>0.011791</td>\n",
              "      <td>0.623188</td>\n",
              "      <td>0.521739</td>\n",
              "      <td>0.236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.627907</td>\n",
              "      <td>0.008043</td>\n",
              "      <td>0.015306</td>\n",
              "      <td>0.058134</td>\n",
              "      <td>0.002010</td>\n",
              "      <td>0.002033</td>\n",
              "      <td>0.594203</td>\n",
              "      <td>0.543478</td>\n",
              "      <td>0.280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.046917</td>\n",
              "      <td>0.096939</td>\n",
              "      <td>0.064485</td>\n",
              "      <td>0.008543</td>\n",
              "      <td>0.009961</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.326087</td>\n",
              "      <td>0.040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30686</th>\n",
              "      <td>0.534884</td>\n",
              "      <td>0.024129</td>\n",
              "      <td>0.045918</td>\n",
              "      <td>0.267220</td>\n",
              "      <td>0.003518</td>\n",
              "      <td>0.003659</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.369565</td>\n",
              "      <td>0.100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30687</th>\n",
              "      <td>0.593023</td>\n",
              "      <td>0.033512</td>\n",
              "      <td>0.061224</td>\n",
              "      <td>0.204690</td>\n",
              "      <td>0.006030</td>\n",
              "      <td>0.004879</td>\n",
              "      <td>0.623188</td>\n",
              "      <td>0.326087</td>\n",
              "      <td>0.080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30688</th>\n",
              "      <td>0.581395</td>\n",
              "      <td>0.085791</td>\n",
              "      <td>0.147959</td>\n",
              "      <td>0.234001</td>\n",
              "      <td>0.053266</td>\n",
              "      <td>0.011384</td>\n",
              "      <td>0.536232</td>\n",
              "      <td>0.478261</td>\n",
              "      <td>0.240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30689</th>\n",
              "      <td>0.511628</td>\n",
              "      <td>0.020107</td>\n",
              "      <td>0.045918</td>\n",
              "      <td>0.082071</td>\n",
              "      <td>0.003015</td>\n",
              "      <td>0.009148</td>\n",
              "      <td>0.231884</td>\n",
              "      <td>0.152174</td>\n",
              "      <td>0.120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30690</th>\n",
              "      <td>0.302326</td>\n",
              "      <td>0.036193</td>\n",
              "      <td>0.076531</td>\n",
              "      <td>0.092819</td>\n",
              "      <td>0.035176</td>\n",
              "      <td>0.080504</td>\n",
              "      <td>0.594203</td>\n",
              "      <td>0.652174</td>\n",
              "      <td>0.400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30691 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8e531de5-c9d8-455b-a3b2-96edcd6d9614')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8e531de5-c9d8-455b-a3b2-96edcd6d9614 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8e531de5-c9d8-455b-a3b2-96edcd6d9614');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vk_uo90ezl_T",
        "outputId": "58e8f70a-5f19-4ca6-b05b-deb768e77e80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0\n",
              "1    0\n",
              "2    0\n",
              "3    0\n",
              "4    0\n",
              "5    0\n",
              "6    0\n",
              "7    0\n",
              "8    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainX,testX,trainY,testY=train_test_split(df,y,train_size=0.3,random_state=101)"
      ],
      "metadata": {
        "id": "KIk-TxOOI1E6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = DecisionTreeClassifier()\n",
        "\n",
        "# Train Decision Tree Classifer\n",
        "clf = clf.fit(trainX,trainY)"
      ],
      "metadata": {
        "id": "YU4I1C8kld7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = clf.predict(testX)\n",
        "y_pred_tr=clf.predict(trainX)\n",
        "print(y_pred)\n",
        "print(y_pred_tr)"
      ],
      "metadata": {
        "id": "KSjmkqsu1_V7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e392ddf4-7e1d-4d57-ee07-e5a08127b5f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 ... 0 0 0]\n",
            "[1 1 0 ... 0 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "testa=[metrics.accuracy_score(testY, y_pred)]\n",
        "traina=[clf.score(trainX, trainY)]\n",
        "print(\"testing Accuracy:\",metrics.accuracy_score(testY, y_pred))\n",
        "print(\" Training Accuracy\",clf.score(trainX, trainY))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3evtQ_NI2JFG",
        "outputId": "5ed4f280-e919-4b30-f687-ff6577417814"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "testing Accuracy: 0.9850586482964067\n",
            " Training Accuracy 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(testY, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4HKwdhDUJ2h",
        "outputId": "d95ccd96-a3df-46ed-bed2-c14f3a719743"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[15136,   147],\n",
              "       [  174,  6027]])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "_ZxHNlaX1S6l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(trainY, y_pred_tr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBGE3fZRTuOG",
        "outputId": "7a81bb9c-3568-403a-c8cb-d97347f9c769"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6634,    0],\n",
              "       [   0, 2573]])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model = LogisticRegression()\n",
        "lr_model.fit(trainX,trainY)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgzvAC8yRS-h",
        "outputId": "14151aab-080d-4825-e89e-e4c97d61475e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_train = lr_model.predict(trainX)\n",
        "y_pred_test = lr_model.predict(testX)\n",
        "print(\" Training Accuracy\",lr_model.score(trainX, trainY))\n",
        "print(\" Testing Accuracy\",lr_model.score(testX, testY))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdgg6NqxRqs_",
        "outputId": "d5872ea4-d82b-4b3f-852d-dcc12692889c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Training Accuracy 0.7199956554795265\n",
            " Testing Accuracy 0.7109011357289146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(testY, y_pred_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDkwiBt4TTl_",
        "outputId": "e8a4db55-b54f-4108-b443-bff937312f90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[15117,   166],\n",
              "       [ 6045,   156]])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(trainY, y_pred_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjgeYQb_SAso",
        "outputId": "4b6cc834-3f6b-49ed-a6ca-bc444b274ae0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6552,   82],\n",
              "       [2496,   77]])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Result-1 means not having disease\n",
        "#Result-2 means having disease"
      ],
      "metadata": {
        "id": "BwOoUXoaHof-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "q04i3nM4-6U6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "# Save the model\n",
        "filename = 'model.pkl'\n",
        "pickle.dump(clf, open(filename, 'wb'))\n"
      ],
      "metadata": {
        "id": "tAArk-t83vli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_columns = data1.columns\n",
        "input_data=pd.DataFrame(columns=list_of_columns)\n",
        "input_data.drop(['Result'], axis='columns', inplace=True)\n",
        "\n",
        "input_data.at[0, 'Age of the patient'] = int(input('enter age of the patient'))\n",
        "input_data.at[0, 'Total Bilirubin'] = float(input('enter value of total bilirubin in blood'))\n",
        "input_data.at[0, 'Direct Bilirubin'] = float(input('enter value of direct bilirubin in blood'))\n",
        "input_data.at[0, '\\xa0Alkphos Alkaline Phosphotase'] = int(input('enter value of alkphos alkaline in blood'))\n",
        "input_data.at[0, '\\xa0Sgpt Alamine Aminotransferase'] = int(input('enter value of sgpt alamine in blood'))\n",
        "input_data.at[0, 'Sgot Aspartate Aminotransferase'] = int(input('enter value of sgot asparatate in blood'))\n",
        "input_data.at[0, 'Total Protiens'] = float(input('enter value of total protiens in blood'))\n",
        "input_data.at[0, '\\xa0ALB Albumin'] = float(input('enter alb albumin in blood'))\n",
        "input_data.at[0, 'A/G Ratio Albumin and Globulin Ratio'] = float(input('enter value of a/g ratio albumin and globulin ratio'))\n",
        "input_data['Age of the patient']=(input_data['Age of the patient']-data1['Age of the patient'].min())/(data1['Age of the patient'].max()-data1['Age of the patient'].min())\n",
        "input_data['Total Bilirubin']=(input_data['Total Bilirubin']-data1['Total Bilirubin'].min())/(data1['Total Bilirubin'].max()-data1['Total Bilirubin'].min())\n",
        "input_data['Direct Bilirubin']=(input_data['Direct Bilirubin']-data1['Direct Bilirubin'].min())/(data1['Direct Bilirubin'].max()-data1['Direct Bilirubin'].min())\n",
        "input_data['\\xa0Alkphos Alkaline Phosphotase']=(input_data['\\xa0Alkphos Alkaline Phosphotase']-data1['\\xa0Alkphos Alkaline Phosphotase'].min())/(data1['\\xa0Alkphos Alkaline Phosphotase'].max()-data1['\\xa0Alkphos Alkaline Phosphotase'].min())\n",
        "input_data['\\xa0Sgpt Alamine Aminotransferase']=(input_data['\\xa0Sgpt Alamine Aminotransferase']-data1['\\xa0Sgpt Alamine Aminotransferase'].min())/(data1['\\xa0Sgpt Alamine Aminotransferase'].max()-data1['\\xa0Sgpt Alamine Aminotransferase'].min())\n",
        "input_data['Total Protiens']=(input_data['Total Protiens']-data1['Total Protiens'].min())/(data1['Total Protiens'].max()-data1['Total Protiens'].min())\n",
        "input_data['\\xa0ALB Albumin']=(input_data['\\xa0ALB Albumin']-data1['\\xa0ALB Albumin'].min())/(data1['\\xa0ALB Albumin'].max()-data1['\\xa0ALB Albumin'].min())\n",
        "input_data['A/G Ratio Albumin and Globulin Ratio']=(input_data['A/G Ratio Albumin and Globulin Ratio']-data1['A/G Ratio Albumin and Globulin Ratio'].min())/(data1['A/G Ratio Albumin and Globulin Ratio'].max()-data1['A/G Ratio Albumin and Globulin Ratio'].min())\n",
        "model = pickle.load(open('model.pkl', 'rb'))\n",
        "prediction = model.predict(input_data)\n",
        "result = prediction[0]\n",
        "predict=result*(data1['Result'].max()-data1['Result'].min())+data1['Result'].min()\n",
        "print('result',predict)\n",
        "if predict==1:\n",
        "  print('having  liver cancer disease')\n",
        "else:\n",
        "  print('not having liver cancer disease')"
      ],
      "metadata": {
        "id": "V33YR3ukADVR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abe523c8-1f21-4502-d44e-48b8fe59cfbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter age of the patient8\n",
            "enter value of total bilirubin in blood5.5\n",
            "enter value of direct bilirubin in blood8.3\n",
            "enter value of alkphos alkaline in blood8\n",
            "enter value of sgpt alamine in blood9\n",
            "enter value of sgot asparatate in blood400\n",
            "enter value of total protiens in blood76.8\n",
            "enter alb albumin in blood87.5\n",
            "enter value of a/g ratio albumin and globulin ratio6.5\n",
            "result 1\n",
            "having  liver cancer disease\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras  #Keras is the deep learning library that helps you to code Deep Neural Networks with fewer lines of code\n",
        "#from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import RMSprop,Adadelta,SGD,Adagrad,Adam,Adamax,Nadam\n",
        "#import pylab as plt\n",
        "#import seaborn as sns #For data visualization\n",
        "import pandas as pd # For Data manipulation"
      ],
      "metadata": {
        "id": "gSwGjZDpzBu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data1.fillna(data1.mean(),inplace=True)"
      ],
      "metadata": {
        "id": "k-dED3Sw9F85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data1.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZA3n0C99NjY",
        "outputId": "704cedd4-8d16-4803-8bad-f9bbb044517f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Age of the patient                      0\n",
              "Total Bilirubin                         0\n",
              "Direct Bilirubin                        0\n",
              " Alkphos Alkaline Phosphotase           0\n",
              " Sgpt Alamine Aminotransferase          0\n",
              "Sgot Aspartate Aminotransferase         0\n",
              "Total Protiens                          0\n",
              " ALB Albumin                            0\n",
              "A/G Ratio Albumin and Globulin Ratio    0\n",
              "Result                                  0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "ms=MinMaxScaler()\n",
        "datanew=ms.fit_transform(data1)\n",
        "print(datanew)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-yk0IjU1cY4",
        "outputId": "8862be51-0378-49f8-be72-def6b11a39da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.70930233 0.00402145 0.         ... 0.52173913 0.24       0.        ]\n",
            " [0.6744186  0.14075067 0.2755102  ... 0.5        0.176      0.        ]\n",
            " [0.6744186  0.0924933  0.20408163 ... 0.52173913 0.236      0.        ]\n",
            " ...\n",
            " [0.58139535 0.08579088 0.14795918 ... 0.47826087 0.24       0.        ]\n",
            " [0.51162791 0.02010724 0.04591837 ... 0.15217391 0.12       0.        ]\n",
            " [0.30232558 0.03619303 0.07653061 ... 0.65217391 0.4        0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=pd.DataFrame(data=datanew[0:,0:]) "
      ],
      "metadata": {
        "id": "cNR38FoP11bR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "V2wCfUzjeyeh",
        "outputId": "97cd7d87-ed03-4749-e7bf-4377ae65bdb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              0         1         2         3         4         5         6  \\\n",
              "0      0.709302  0.004021  0.000000  0.060576  0.003015  0.001626  0.594203   \n",
              "1      0.674419  0.140751  0.275510  0.310699  0.027136  0.018296  0.695652   \n",
              "2      0.674419  0.092493  0.204082  0.208598  0.025126  0.011791  0.623188   \n",
              "3      0.627907  0.008043  0.015306  0.058134  0.002010  0.002033  0.594203   \n",
              "4      0.790698  0.046917  0.096939  0.064485  0.008543  0.009961  0.666667   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "30686  0.534884  0.024129  0.045918  0.267220  0.003518  0.003659  0.666667   \n",
              "30687  0.593023  0.033512  0.061224  0.204690  0.006030  0.004879  0.623188   \n",
              "30688  0.581395  0.085791  0.147959  0.234001  0.053266  0.011384  0.536232   \n",
              "30689  0.511628  0.020107  0.045918  0.082071  0.003015  0.009148  0.231884   \n",
              "30690  0.302326  0.036193  0.076531  0.092819  0.035176  0.080504  0.594203   \n",
              "\n",
              "              7      8    9  \n",
              "0      0.521739  0.240  0.0  \n",
              "1      0.500000  0.176  0.0  \n",
              "2      0.521739  0.236  0.0  \n",
              "3      0.543478  0.280  0.0  \n",
              "4      0.326087  0.040  0.0  \n",
              "...         ...    ...  ...  \n",
              "30686  0.369565  0.100  0.0  \n",
              "30687  0.326087  0.080  0.0  \n",
              "30688  0.478261  0.240  0.0  \n",
              "30689  0.152174  0.120  0.0  \n",
              "30690  0.652174  0.400  0.0  \n",
              "\n",
              "[30691 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-09e5eafe-48bf-43a1-bb8e-9e4c721c4b6a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.709302</td>\n",
              "      <td>0.004021</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.060576</td>\n",
              "      <td>0.003015</td>\n",
              "      <td>0.001626</td>\n",
              "      <td>0.594203</td>\n",
              "      <td>0.521739</td>\n",
              "      <td>0.240</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.674419</td>\n",
              "      <td>0.140751</td>\n",
              "      <td>0.275510</td>\n",
              "      <td>0.310699</td>\n",
              "      <td>0.027136</td>\n",
              "      <td>0.018296</td>\n",
              "      <td>0.695652</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.176</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.674419</td>\n",
              "      <td>0.092493</td>\n",
              "      <td>0.204082</td>\n",
              "      <td>0.208598</td>\n",
              "      <td>0.025126</td>\n",
              "      <td>0.011791</td>\n",
              "      <td>0.623188</td>\n",
              "      <td>0.521739</td>\n",
              "      <td>0.236</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.627907</td>\n",
              "      <td>0.008043</td>\n",
              "      <td>0.015306</td>\n",
              "      <td>0.058134</td>\n",
              "      <td>0.002010</td>\n",
              "      <td>0.002033</td>\n",
              "      <td>0.594203</td>\n",
              "      <td>0.543478</td>\n",
              "      <td>0.280</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.046917</td>\n",
              "      <td>0.096939</td>\n",
              "      <td>0.064485</td>\n",
              "      <td>0.008543</td>\n",
              "      <td>0.009961</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.326087</td>\n",
              "      <td>0.040</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30686</th>\n",
              "      <td>0.534884</td>\n",
              "      <td>0.024129</td>\n",
              "      <td>0.045918</td>\n",
              "      <td>0.267220</td>\n",
              "      <td>0.003518</td>\n",
              "      <td>0.003659</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.369565</td>\n",
              "      <td>0.100</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30687</th>\n",
              "      <td>0.593023</td>\n",
              "      <td>0.033512</td>\n",
              "      <td>0.061224</td>\n",
              "      <td>0.204690</td>\n",
              "      <td>0.006030</td>\n",
              "      <td>0.004879</td>\n",
              "      <td>0.623188</td>\n",
              "      <td>0.326087</td>\n",
              "      <td>0.080</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30688</th>\n",
              "      <td>0.581395</td>\n",
              "      <td>0.085791</td>\n",
              "      <td>0.147959</td>\n",
              "      <td>0.234001</td>\n",
              "      <td>0.053266</td>\n",
              "      <td>0.011384</td>\n",
              "      <td>0.536232</td>\n",
              "      <td>0.478261</td>\n",
              "      <td>0.240</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30689</th>\n",
              "      <td>0.511628</td>\n",
              "      <td>0.020107</td>\n",
              "      <td>0.045918</td>\n",
              "      <td>0.082071</td>\n",
              "      <td>0.003015</td>\n",
              "      <td>0.009148</td>\n",
              "      <td>0.231884</td>\n",
              "      <td>0.152174</td>\n",
              "      <td>0.120</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30690</th>\n",
              "      <td>0.302326</td>\n",
              "      <td>0.036193</td>\n",
              "      <td>0.076531</td>\n",
              "      <td>0.092819</td>\n",
              "      <td>0.035176</td>\n",
              "      <td>0.080504</td>\n",
              "      <td>0.594203</td>\n",
              "      <td>0.652174</td>\n",
              "      <td>0.400</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30691 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-09e5eafe-48bf-43a1-bb8e-9e4c721c4b6a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-09e5eafe-48bf-43a1-bb8e-9e4c721c4b6a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-09e5eafe-48bf-43a1-bb8e-9e4c721c4b6a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=dataset.iloc[:,0:9].values\n",
        "Y=dataset.iloc[:,9:].values"
      ],
      "metadata": {
        "id": "PINMfBfT1-3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=1)\n",
        "print(y_test)\n",
        "print(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ww1XuQnF5MdW",
        "outputId": "38f4573c-5675-4b19-9515-bb2ac3911430"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " ...\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]]\n",
            "[[0.75581395 0.00402145 0.00510204 ... 0.4057971  0.30434783 0.164     ]\n",
            " [0.70930233 0.01742627 0.02040816 ... 0.43478261 0.47826087 0.32      ]\n",
            " [0.30232558 0.04691689 0.09693878 ... 0.66666667 0.32608696 0.04      ]\n",
            " ...\n",
            " [0.80232558 0.01608579 0.03571429 ... 0.46376812 0.43478261 0.264     ]\n",
            " [0.65116279 0.01474531 0.0255102  ... 0.26086957 0.23913043 0.2       ]\n",
            " [0.34883721 0.00670241 0.00510204 ... 0.60869565 0.60869565 0.32      ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "First_Layer_Size = 64# Number of neurons in first layer\n",
        "model=Sequential()\n",
        "model.add(Dense(First_Layer_Size,activation='relu', input_shape=(9,)))\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dense(120,activation='relu'))\n",
        "model.add(Dense(120,activation='relu'))\n",
        "model.add(Dense(120,activation='relu'))\n",
        "model.add(Dense(64,activation='tanh'))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnH_mVsD5Xmv",
        "outputId": "ab39e184-6317-41ff-d23e-7430aa10bc93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_7 (Dense)             (None, 64)                640       \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 120)               7800      \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 120)               14520     \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 120)               14520     \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 64)                7744      \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 49,449\n",
            "Trainable params: 49,449\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='Adadelta', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "utTHNyuC5eV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train,y_train,batch_size=1,epochs=500,verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsJGmf9d5i6C",
        "outputId": "178f66d8-3a5d-4611-ad80-efa1b8c7e00e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.6063 - accuracy: 0.7142\n",
            "Epoch 2/500\n",
            "21483/21483 [==============================] - 37s 2ms/step - loss: 0.5872 - accuracy: 0.7142\n",
            "Epoch 3/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5774 - accuracy: 0.7142\n",
            "Epoch 4/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5655 - accuracy: 0.7142\n",
            "Epoch 5/500\n",
            "21483/21483 [==============================] - 40s 2ms/step - loss: 0.5526 - accuracy: 0.7142\n",
            "Epoch 6/500\n",
            "21483/21483 [==============================] - 37s 2ms/step - loss: 0.5409 - accuracy: 0.7142\n",
            "Epoch 7/500\n",
            "21483/21483 [==============================] - 37s 2ms/step - loss: 0.5319 - accuracy: 0.7142\n",
            "Epoch 8/500\n",
            "21483/21483 [==============================] - 37s 2ms/step - loss: 0.5253 - accuracy: 0.7142\n",
            "Epoch 9/500\n",
            "21483/21483 [==============================] - 37s 2ms/step - loss: 0.5209 - accuracy: 0.7142\n",
            "Epoch 10/500\n",
            "21483/21483 [==============================] - 37s 2ms/step - loss: 0.5178 - accuracy: 0.7142\n",
            "Epoch 11/500\n",
            "21483/21483 [==============================] - 37s 2ms/step - loss: 0.5157 - accuracy: 0.7156\n",
            "Epoch 12/500\n",
            "21483/21483 [==============================] - 37s 2ms/step - loss: 0.5139 - accuracy: 0.7163\n",
            "Epoch 13/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5127 - accuracy: 0.7181\n",
            "Epoch 14/500\n",
            "21483/21483 [==============================] - 37s 2ms/step - loss: 0.5117 - accuracy: 0.7187\n",
            "Epoch 15/500\n",
            "21483/21483 [==============================] - 37s 2ms/step - loss: 0.5108 - accuracy: 0.7214\n",
            "Epoch 16/500\n",
            "21483/21483 [==============================] - 37s 2ms/step - loss: 0.5101 - accuracy: 0.7231\n",
            "Epoch 17/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5093 - accuracy: 0.7230\n",
            "Epoch 18/500\n",
            "21483/21483 [==============================] - 37s 2ms/step - loss: 0.5087 - accuracy: 0.7219\n",
            "Epoch 19/500\n",
            "21483/21483 [==============================] - 37s 2ms/step - loss: 0.5081 - accuracy: 0.7219\n",
            "Epoch 20/500\n",
            "21483/21483 [==============================] - 37s 2ms/step - loss: 0.5077 - accuracy: 0.7211\n",
            "Epoch 21/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5072 - accuracy: 0.7212\n",
            "Epoch 22/500\n",
            "21483/21483 [==============================] - 37s 2ms/step - loss: 0.5067 - accuracy: 0.7208\n",
            "Epoch 23/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5064 - accuracy: 0.7226\n",
            "Epoch 24/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5059 - accuracy: 0.7222\n",
            "Epoch 25/500\n",
            "21483/21483 [==============================] - 37s 2ms/step - loss: 0.5057 - accuracy: 0.7219\n",
            "Epoch 26/500\n",
            "21483/21483 [==============================] - 37s 2ms/step - loss: 0.5052 - accuracy: 0.7222\n",
            "Epoch 27/500\n",
            "21483/21483 [==============================] - 37s 2ms/step - loss: 0.5051 - accuracy: 0.7214\n",
            "Epoch 28/500\n",
            "21483/21483 [==============================] - 37s 2ms/step - loss: 0.5048 - accuracy: 0.7225\n",
            "Epoch 29/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5045 - accuracy: 0.7203\n",
            "Epoch 30/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5044 - accuracy: 0.7215\n",
            "Epoch 31/500\n",
            "21483/21483 [==============================] - 37s 2ms/step - loss: 0.5041 - accuracy: 0.7213\n",
            "Epoch 32/500\n",
            "21483/21483 [==============================] - 37s 2ms/step - loss: 0.5038 - accuracy: 0.7197\n",
            "Epoch 33/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5037 - accuracy: 0.7197\n",
            "Epoch 34/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5035 - accuracy: 0.7195\n",
            "Epoch 35/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5033 - accuracy: 0.7213\n",
            "Epoch 36/500\n",
            "21483/21483 [==============================] - 37s 2ms/step - loss: 0.5030 - accuracy: 0.7192\n",
            "Epoch 37/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5031 - accuracy: 0.7196\n",
            "Epoch 38/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5029 - accuracy: 0.7182\n",
            "Epoch 39/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5029 - accuracy: 0.7186\n",
            "Epoch 40/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5026 - accuracy: 0.7188\n",
            "Epoch 41/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5024 - accuracy: 0.7180\n",
            "Epoch 42/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5024 - accuracy: 0.7190\n",
            "Epoch 43/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5023 - accuracy: 0.7193\n",
            "Epoch 44/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5021 - accuracy: 0.7179\n",
            "Epoch 45/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5021 - accuracy: 0.7186\n",
            "Epoch 46/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5020 - accuracy: 0.7187\n",
            "Epoch 47/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5018 - accuracy: 0.7182\n",
            "Epoch 48/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5016 - accuracy: 0.7187\n",
            "Epoch 49/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5017 - accuracy: 0.7187\n",
            "Epoch 50/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5015 - accuracy: 0.7191\n",
            "Epoch 51/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5014 - accuracy: 0.7195\n",
            "Epoch 52/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5013 - accuracy: 0.7188\n",
            "Epoch 53/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5013 - accuracy: 0.7180\n",
            "Epoch 54/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5012 - accuracy: 0.7201\n",
            "Epoch 55/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5011 - accuracy: 0.7208\n",
            "Epoch 56/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5011 - accuracy: 0.7199\n",
            "Epoch 57/500\n",
            "21483/21483 [==============================] - 37s 2ms/step - loss: 0.5011 - accuracy: 0.7201\n",
            "Epoch 58/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5011 - accuracy: 0.7205\n",
            "Epoch 59/500\n",
            "21483/21483 [==============================] - 37s 2ms/step - loss: 0.5010 - accuracy: 0.7208\n",
            "Epoch 60/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5010 - accuracy: 0.7186\n",
            "Epoch 61/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5011 - accuracy: 0.7201\n",
            "Epoch 62/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5009 - accuracy: 0.7209\n",
            "Epoch 63/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5008 - accuracy: 0.7214\n",
            "Epoch 64/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5008 - accuracy: 0.7204\n",
            "Epoch 65/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5006 - accuracy: 0.7190\n",
            "Epoch 66/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5004 - accuracy: 0.7202\n",
            "Epoch 67/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5005 - accuracy: 0.7201\n",
            "Epoch 68/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5004 - accuracy: 0.7186\n",
            "Epoch 69/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5004 - accuracy: 0.7204\n",
            "Epoch 70/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5003 - accuracy: 0.7206\n",
            "Epoch 71/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5001 - accuracy: 0.7200\n",
            "Epoch 72/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5002 - accuracy: 0.7210\n",
            "Epoch 73/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5002 - accuracy: 0.7204\n",
            "Epoch 74/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5000 - accuracy: 0.7196\n",
            "Epoch 75/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5001 - accuracy: 0.7203\n",
            "Epoch 76/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5000 - accuracy: 0.7196\n",
            "Epoch 77/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5000 - accuracy: 0.7207\n",
            "Epoch 78/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4999 - accuracy: 0.7214\n",
            "Epoch 79/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4999 - accuracy: 0.7182\n",
            "Epoch 80/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4999 - accuracy: 0.7207\n",
            "Epoch 81/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4999 - accuracy: 0.7211\n",
            "Epoch 82/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4997 - accuracy: 0.7184\n",
            "Epoch 83/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4998 - accuracy: 0.7196\n",
            "Epoch 84/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4997 - accuracy: 0.7213\n",
            "Epoch 85/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4999 - accuracy: 0.7195\n",
            "Epoch 86/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4997 - accuracy: 0.7179\n",
            "Epoch 87/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4998 - accuracy: 0.7211\n",
            "Epoch 88/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4998 - accuracy: 0.7200\n",
            "Epoch 89/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4998 - accuracy: 0.7189\n",
            "Epoch 90/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4998 - accuracy: 0.7188\n",
            "Epoch 91/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4996 - accuracy: 0.7194\n",
            "Epoch 92/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4997 - accuracy: 0.7202\n",
            "Epoch 93/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4996 - accuracy: 0.7192\n",
            "Epoch 94/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4994 - accuracy: 0.7201\n",
            "Epoch 95/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4996 - accuracy: 0.7190\n",
            "Epoch 96/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4996 - accuracy: 0.7190\n",
            "Epoch 97/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4995 - accuracy: 0.7188\n",
            "Epoch 98/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4995 - accuracy: 0.7195\n",
            "Epoch 99/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4995 - accuracy: 0.7198\n",
            "Epoch 100/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.4995 - accuracy: 0.7195\n",
            "Epoch 101/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4994 - accuracy: 0.7189\n",
            "Epoch 102/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4996 - accuracy: 0.7204\n",
            "Epoch 103/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.4995 - accuracy: 0.7199\n",
            "Epoch 104/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4994 - accuracy: 0.7184\n",
            "Epoch 105/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4996 - accuracy: 0.7197\n",
            "Epoch 106/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4993 - accuracy: 0.7188\n",
            "Epoch 107/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4995 - accuracy: 0.7202\n",
            "Epoch 108/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.4995 - accuracy: 0.7185\n",
            "Epoch 109/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4993 - accuracy: 0.7206\n",
            "Epoch 110/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4993 - accuracy: 0.7178\n",
            "Epoch 111/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4994 - accuracy: 0.7202\n",
            "Epoch 112/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4994 - accuracy: 0.7186\n",
            "Epoch 113/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4994 - accuracy: 0.7201\n",
            "Epoch 114/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4993 - accuracy: 0.7185\n",
            "Epoch 115/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.4994 - accuracy: 0.7192\n",
            "Epoch 116/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.4993 - accuracy: 0.7190\n",
            "Epoch 117/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4993 - accuracy: 0.7203\n",
            "Epoch 118/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4993 - accuracy: 0.7213\n",
            "Epoch 119/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.4993 - accuracy: 0.7199\n",
            "Epoch 120/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4993 - accuracy: 0.7190\n",
            "Epoch 121/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4994 - accuracy: 0.7209\n",
            "Epoch 122/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4994 - accuracy: 0.7197\n",
            "Epoch 123/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4993 - accuracy: 0.7216\n",
            "Epoch 124/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.4993 - accuracy: 0.7190\n",
            "Epoch 125/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4991 - accuracy: 0.7204\n",
            "Epoch 126/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4992 - accuracy: 0.7188\n",
            "Epoch 127/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4993 - accuracy: 0.7207\n",
            "Epoch 128/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4992 - accuracy: 0.7215\n",
            "Epoch 129/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4994 - accuracy: 0.7198\n",
            "Epoch 130/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4992 - accuracy: 0.7204\n",
            "Epoch 131/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4993 - accuracy: 0.7193\n",
            "Epoch 132/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.4993 - accuracy: 0.7202\n",
            "Epoch 133/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4993 - accuracy: 0.7216\n",
            "Epoch 134/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4992 - accuracy: 0.7186\n",
            "Epoch 135/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.4994 - accuracy: 0.7213\n",
            "Epoch 136/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4996 - accuracy: 0.7194\n",
            "Epoch 137/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.4995 - accuracy: 0.7200\n",
            "Epoch 138/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4994 - accuracy: 0.7213\n",
            "Epoch 139/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.4995 - accuracy: 0.7205\n",
            "Epoch 140/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4995 - accuracy: 0.7196\n",
            "Epoch 141/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4996 - accuracy: 0.7208\n",
            "Epoch 142/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4995 - accuracy: 0.7208\n",
            "Epoch 143/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4994 - accuracy: 0.7214\n",
            "Epoch 144/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4997 - accuracy: 0.7192\n",
            "Epoch 145/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4998 - accuracy: 0.7202\n",
            "Epoch 146/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4995 - accuracy: 0.7197\n",
            "Epoch 147/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4996 - accuracy: 0.7196\n",
            "Epoch 148/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4996 - accuracy: 0.7200\n",
            "Epoch 149/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4996 - accuracy: 0.7202\n",
            "Epoch 150/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4996 - accuracy: 0.7192\n",
            "Epoch 151/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4999 - accuracy: 0.7203\n",
            "Epoch 152/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4998 - accuracy: 0.7217\n",
            "Epoch 153/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4996 - accuracy: 0.7220\n",
            "Epoch 154/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4998 - accuracy: 0.7202\n",
            "Epoch 155/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4997 - accuracy: 0.7222\n",
            "Epoch 156/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4998 - accuracy: 0.7196\n",
            "Epoch 157/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4998 - accuracy: 0.7197\n",
            "Epoch 158/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4995 - accuracy: 0.7196\n",
            "Epoch 159/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4997 - accuracy: 0.7209\n",
            "Epoch 160/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4998 - accuracy: 0.7198\n",
            "Epoch 161/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5001 - accuracy: 0.7209\n",
            "Epoch 162/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4999 - accuracy: 0.7213\n",
            "Epoch 163/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.4998 - accuracy: 0.7205\n",
            "Epoch 164/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5000 - accuracy: 0.7211\n",
            "Epoch 165/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5001 - accuracy: 0.7215\n",
            "Epoch 166/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5000 - accuracy: 0.7237\n",
            "Epoch 167/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5000 - accuracy: 0.7205\n",
            "Epoch 168/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4999 - accuracy: 0.7206\n",
            "Epoch 169/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5002 - accuracy: 0.7208\n",
            "Epoch 170/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5000 - accuracy: 0.7222\n",
            "Epoch 171/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5002 - accuracy: 0.7217\n",
            "Epoch 172/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5002 - accuracy: 0.7197\n",
            "Epoch 173/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5001 - accuracy: 0.7216\n",
            "Epoch 174/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5003 - accuracy: 0.7222\n",
            "Epoch 175/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.4998 - accuracy: 0.7221\n",
            "Epoch 176/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5001 - accuracy: 0.7223\n",
            "Epoch 177/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5002 - accuracy: 0.7233\n",
            "Epoch 178/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5003 - accuracy: 0.7216\n",
            "Epoch 179/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5001 - accuracy: 0.7215\n",
            "Epoch 180/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5003 - accuracy: 0.7228\n",
            "Epoch 181/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5004 - accuracy: 0.7222\n",
            "Epoch 182/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5004 - accuracy: 0.7226\n",
            "Epoch 183/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5003 - accuracy: 0.7215\n",
            "Epoch 184/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5004 - accuracy: 0.7215\n",
            "Epoch 185/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5005 - accuracy: 0.7212\n",
            "Epoch 186/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5006 - accuracy: 0.7220\n",
            "Epoch 187/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5006 - accuracy: 0.7219\n",
            "Epoch 188/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5005 - accuracy: 0.7228\n",
            "Epoch 189/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5007 - accuracy: 0.7210\n",
            "Epoch 190/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5007 - accuracy: 0.7227\n",
            "Epoch 191/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5009 - accuracy: 0.7215\n",
            "Epoch 192/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5009 - accuracy: 0.7208\n",
            "Epoch 193/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5007 - accuracy: 0.7244\n",
            "Epoch 194/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5006 - accuracy: 0.7242\n",
            "Epoch 195/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5008 - accuracy: 0.7225\n",
            "Epoch 196/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5011 - accuracy: 0.7230\n",
            "Epoch 197/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5010 - accuracy: 0.7230\n",
            "Epoch 198/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5009 - accuracy: 0.7234\n",
            "Epoch 199/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5008 - accuracy: 0.7229\n",
            "Epoch 200/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5008 - accuracy: 0.7223\n",
            "Epoch 201/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5009 - accuracy: 0.7241\n",
            "Epoch 202/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5009 - accuracy: 0.7229\n",
            "Epoch 203/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5010 - accuracy: 0.7233\n",
            "Epoch 204/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5010 - accuracy: 0.7222\n",
            "Epoch 205/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5011 - accuracy: 0.7232\n",
            "Epoch 206/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5008 - accuracy: 0.7228\n",
            "Epoch 207/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5010 - accuracy: 0.7235\n",
            "Epoch 208/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5011 - accuracy: 0.7241\n",
            "Epoch 209/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5010 - accuracy: 0.7245\n",
            "Epoch 210/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5011 - accuracy: 0.7225\n",
            "Epoch 211/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5010 - accuracy: 0.7238\n",
            "Epoch 212/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5011 - accuracy: 0.7232\n",
            "Epoch 213/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5010 - accuracy: 0.7259\n",
            "Epoch 214/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5012 - accuracy: 0.7250\n",
            "Epoch 215/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5014 - accuracy: 0.7241\n",
            "Epoch 216/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5014 - accuracy: 0.7239\n",
            "Epoch 217/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5013 - accuracy: 0.7245\n",
            "Epoch 218/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5012 - accuracy: 0.7250\n",
            "Epoch 219/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5016 - accuracy: 0.7259\n",
            "Epoch 220/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5015 - accuracy: 0.7256\n",
            "Epoch 221/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5014 - accuracy: 0.7258\n",
            "Epoch 222/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5015 - accuracy: 0.7238\n",
            "Epoch 223/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5017 - accuracy: 0.7258\n",
            "Epoch 224/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5015 - accuracy: 0.7250\n",
            "Epoch 225/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5016 - accuracy: 0.7261\n",
            "Epoch 226/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5018 - accuracy: 0.7258\n",
            "Epoch 227/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5016 - accuracy: 0.7254\n",
            "Epoch 228/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5020 - accuracy: 0.7256\n",
            "Epoch 229/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5018 - accuracy: 0.7243\n",
            "Epoch 230/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5019 - accuracy: 0.7257\n",
            "Epoch 231/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5020 - accuracy: 0.7269\n",
            "Epoch 232/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5018 - accuracy: 0.7269\n",
            "Epoch 233/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5021 - accuracy: 0.7270\n",
            "Epoch 234/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5021 - accuracy: 0.7258\n",
            "Epoch 235/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5020 - accuracy: 0.7276\n",
            "Epoch 236/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5025 - accuracy: 0.7270\n",
            "Epoch 237/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5020 - accuracy: 0.7266\n",
            "Epoch 238/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5023 - accuracy: 0.7261\n",
            "Epoch 239/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5021 - accuracy: 0.7295\n",
            "Epoch 240/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5022 - accuracy: 0.7264\n",
            "Epoch 241/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5024 - accuracy: 0.7271\n",
            "Epoch 242/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5023 - accuracy: 0.7279\n",
            "Epoch 243/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5023 - accuracy: 0.7280\n",
            "Epoch 244/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5023 - accuracy: 0.7272\n",
            "Epoch 245/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5024 - accuracy: 0.7268\n",
            "Epoch 246/500\n",
            "21483/21483 [==============================] - 38s 2ms/step - loss: 0.5023 - accuracy: 0.7291\n",
            "Epoch 247/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5026 - accuracy: 0.7295\n",
            "Epoch 248/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5027 - accuracy: 0.7294\n",
            "Epoch 249/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5027 - accuracy: 0.7265\n",
            "Epoch 250/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5026 - accuracy: 0.7292\n",
            "Epoch 251/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5027 - accuracy: 0.7283\n",
            "Epoch 252/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5027 - accuracy: 0.7288\n",
            "Epoch 253/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5030 - accuracy: 0.7292\n",
            "Epoch 254/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5027 - accuracy: 0.7301\n",
            "Epoch 255/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5029 - accuracy: 0.7294\n",
            "Epoch 256/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5032 - accuracy: 0.7288\n",
            "Epoch 257/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5035 - accuracy: 0.7300\n",
            "Epoch 258/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5032 - accuracy: 0.7315\n",
            "Epoch 259/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5029 - accuracy: 0.7300\n",
            "Epoch 260/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5033 - accuracy: 0.7303\n",
            "Epoch 261/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5033 - accuracy: 0.7287\n",
            "Epoch 262/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5033 - accuracy: 0.7312\n",
            "Epoch 263/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5033 - accuracy: 0.7302\n",
            "Epoch 264/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5034 - accuracy: 0.7289\n",
            "Epoch 265/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5031 - accuracy: 0.7304\n",
            "Epoch 266/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5033 - accuracy: 0.7304\n",
            "Epoch 267/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5035 - accuracy: 0.7289\n",
            "Epoch 268/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5032 - accuracy: 0.7312\n",
            "Epoch 269/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5035 - accuracy: 0.7315\n",
            "Epoch 270/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5033 - accuracy: 0.7309\n",
            "Epoch 271/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5032 - accuracy: 0.7302\n",
            "Epoch 272/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5031 - accuracy: 0.7287\n",
            "Epoch 273/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5034 - accuracy: 0.7298\n",
            "Epoch 274/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5032 - accuracy: 0.7305\n",
            "Epoch 275/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5033 - accuracy: 0.7288\n",
            "Epoch 276/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5033 - accuracy: 0.7312\n",
            "Epoch 277/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5032 - accuracy: 0.7310\n",
            "Epoch 278/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5029 - accuracy: 0.7299\n",
            "Epoch 279/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5034 - accuracy: 0.7311\n",
            "Epoch 280/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5032 - accuracy: 0.7305\n",
            "Epoch 281/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5032 - accuracy: 0.7315\n",
            "Epoch 282/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5034 - accuracy: 0.7305\n",
            "Epoch 283/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5035 - accuracy: 0.7317\n",
            "Epoch 284/500\n",
            "21483/21483 [==============================] - 47s 2ms/step - loss: 0.5032 - accuracy: 0.7302\n",
            "Epoch 285/500\n",
            "21483/21483 [==============================] - 42s 2ms/step - loss: 0.5033 - accuracy: 0.7317\n",
            "Epoch 286/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5031 - accuracy: 0.7305\n",
            "Epoch 287/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5033 - accuracy: 0.7316\n",
            "Epoch 288/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5032 - accuracy: 0.7324\n",
            "Epoch 289/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5034 - accuracy: 0.7313\n",
            "Epoch 290/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5033 - accuracy: 0.7318\n",
            "Epoch 291/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5033 - accuracy: 0.7310\n",
            "Epoch 292/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5032 - accuracy: 0.7327\n",
            "Epoch 293/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5032 - accuracy: 0.7336\n",
            "Epoch 294/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5031 - accuracy: 0.7307\n",
            "Epoch 295/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5033 - accuracy: 0.7312\n",
            "Epoch 296/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5034 - accuracy: 0.7324\n",
            "Epoch 297/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5037 - accuracy: 0.7341\n",
            "Epoch 298/500\n",
            "21483/21483 [==============================] - 40s 2ms/step - loss: 0.5034 - accuracy: 0.7335\n",
            "Epoch 299/500\n",
            "21483/21483 [==============================] - 40s 2ms/step - loss: 0.5034 - accuracy: 0.7329\n",
            "Epoch 300/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5035 - accuracy: 0.7326\n",
            "Epoch 301/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5037 - accuracy: 0.7321\n",
            "Epoch 302/500\n",
            "21483/21483 [==============================] - 40s 2ms/step - loss: 0.5033 - accuracy: 0.7336\n",
            "Epoch 303/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5035 - accuracy: 0.7318\n",
            "Epoch 304/500\n",
            "21483/21483 [==============================] - 40s 2ms/step - loss: 0.5034 - accuracy: 0.7333\n",
            "Epoch 305/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5035 - accuracy: 0.7336\n",
            "Epoch 306/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5034 - accuracy: 0.7327\n",
            "Epoch 307/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5032 - accuracy: 0.7336\n",
            "Epoch 308/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5033 - accuracy: 0.7328\n",
            "Epoch 309/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5035 - accuracy: 0.7342\n",
            "Epoch 310/500\n",
            "21483/21483 [==============================] - 40s 2ms/step - loss: 0.5032 - accuracy: 0.7348\n",
            "Epoch 311/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5030 - accuracy: 0.7338\n",
            "Epoch 312/500\n",
            "21483/21483 [==============================] - 40s 2ms/step - loss: 0.5031 - accuracy: 0.7330\n",
            "Epoch 313/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5033 - accuracy: 0.7337\n",
            "Epoch 314/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5032 - accuracy: 0.7330\n",
            "Epoch 315/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5034 - accuracy: 0.7342\n",
            "Epoch 316/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5034 - accuracy: 0.7336\n",
            "Epoch 317/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5034 - accuracy: 0.7326\n",
            "Epoch 318/500\n",
            "21483/21483 [==============================] - 40s 2ms/step - loss: 0.5033 - accuracy: 0.7339\n",
            "Epoch 319/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5033 - accuracy: 0.7336\n",
            "Epoch 320/500\n",
            "21483/21483 [==============================] - 40s 2ms/step - loss: 0.5034 - accuracy: 0.7350\n",
            "Epoch 321/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5030 - accuracy: 0.7342\n",
            "Epoch 322/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5031 - accuracy: 0.7332\n",
            "Epoch 323/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5033 - accuracy: 0.7350\n",
            "Epoch 324/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5028 - accuracy: 0.7343\n",
            "Epoch 325/500\n",
            "21483/21483 [==============================] - 40s 2ms/step - loss: 0.5029 - accuracy: 0.7345\n",
            "Epoch 326/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5032 - accuracy: 0.7340\n",
            "Epoch 327/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5031 - accuracy: 0.7331\n",
            "Epoch 328/500\n",
            "21483/21483 [==============================] - 40s 2ms/step - loss: 0.5031 - accuracy: 0.7341\n",
            "Epoch 329/500\n",
            "21483/21483 [==============================] - 40s 2ms/step - loss: 0.5032 - accuracy: 0.7336\n",
            "Epoch 330/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5031 - accuracy: 0.7347\n",
            "Epoch 331/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5031 - accuracy: 0.7334\n",
            "Epoch 332/500\n",
            "21483/21483 [==============================] - 40s 2ms/step - loss: 0.5028 - accuracy: 0.7329\n",
            "Epoch 333/500\n",
            "21483/21483 [==============================] - 40s 2ms/step - loss: 0.5030 - accuracy: 0.7348\n",
            "Epoch 334/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5029 - accuracy: 0.7325\n",
            "Epoch 335/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5032 - accuracy: 0.7337\n",
            "Epoch 336/500\n",
            "21483/21483 [==============================] - 40s 2ms/step - loss: 0.5028 - accuracy: 0.7342\n",
            "Epoch 337/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5027 - accuracy: 0.7336\n",
            "Epoch 338/500\n",
            "21483/21483 [==============================] - 40s 2ms/step - loss: 0.5028 - accuracy: 0.7343\n",
            "Epoch 339/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5028 - accuracy: 0.7334\n",
            "Epoch 340/500\n",
            "21483/21483 [==============================] - 40s 2ms/step - loss: 0.5026 - accuracy: 0.7346\n",
            "Epoch 341/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5029 - accuracy: 0.7339\n",
            "Epoch 342/500\n",
            "21483/21483 [==============================] - 40s 2ms/step - loss: 0.5030 - accuracy: 0.7331\n",
            "Epoch 343/500\n",
            "21483/21483 [==============================] - 40s 2ms/step - loss: 0.5034 - accuracy: 0.7340\n",
            "Epoch 344/500\n",
            "21483/21483 [==============================] - 40s 2ms/step - loss: 0.5030 - accuracy: 0.7331\n",
            "Epoch 345/500\n",
            "21483/21483 [==============================] - 39s 2ms/step - loss: 0.5031 - accuracy: 0.7336\n",
            "Epoch 346/500\n",
            "21483/21483 [==============================] - 40s 2ms/step - loss: 0.5030 - accuracy: 0.7323\n",
            "Epoch 347/500\n",
            "21483/21483 [==============================] - 40s 2ms/step - loss: 0.5031 - accuracy: 0.7323\n",
            "Epoch 348/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.5028 - accuracy: 0.7336\n",
            "Epoch 349/500\n",
            "21483/21483 [==============================] - 40s 2ms/step - loss: 0.5032 - accuracy: 0.7327\n",
            "Epoch 350/500\n",
            "21483/21483 [==============================] - 40s 2ms/step - loss: 0.5031 - accuracy: 0.7343\n",
            "Epoch 351/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.5026 - accuracy: 0.7333\n",
            "Epoch 352/500\n",
            "21483/21483 [==============================] - 40s 2ms/step - loss: 0.5029 - accuracy: 0.7335\n",
            "Epoch 353/500\n",
            "21483/21483 [==============================] - 40s 2ms/step - loss: 0.5027 - accuracy: 0.7333\n",
            "Epoch 354/500\n",
            "21483/21483 [==============================] - 40s 2ms/step - loss: 0.5026 - accuracy: 0.7336\n",
            "Epoch 355/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.5024 - accuracy: 0.7327\n",
            "Epoch 356/500\n",
            "21483/21483 [==============================] - 40s 2ms/step - loss: 0.5021 - accuracy: 0.7324\n",
            "Epoch 357/500\n",
            "21483/21483 [==============================] - 40s 2ms/step - loss: 0.5025 - accuracy: 0.7327\n",
            "Epoch 358/500\n",
            "21483/21483 [==============================] - 40s 2ms/step - loss: 0.5019 - accuracy: 0.7330\n",
            "Epoch 359/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.5022 - accuracy: 0.7318\n",
            "Epoch 360/500\n",
            "21483/21483 [==============================] - 40s 2ms/step - loss: 0.5018 - accuracy: 0.7341\n",
            "Epoch 361/500\n",
            "21483/21483 [==============================] - 40s 2ms/step - loss: 0.5019 - accuracy: 0.7334\n",
            "Epoch 362/500\n",
            "21483/21483 [==============================] - 40s 2ms/step - loss: 0.5017 - accuracy: 0.7336\n",
            "Epoch 363/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.5016 - accuracy: 0.7324\n",
            "Epoch 364/500\n",
            "21483/21483 [==============================] - 40s 2ms/step - loss: 0.5018 - accuracy: 0.7344\n",
            "Epoch 365/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.5016 - accuracy: 0.7339\n",
            "Epoch 366/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.5013 - accuracy: 0.7350\n",
            "Epoch 367/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.5015 - accuracy: 0.7334\n",
            "Epoch 368/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.5014 - accuracy: 0.7326\n",
            "Epoch 369/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.5010 - accuracy: 0.7326\n",
            "Epoch 370/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.5013 - accuracy: 0.7324\n",
            "Epoch 371/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.5014 - accuracy: 0.7328\n",
            "Epoch 372/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.5014 - accuracy: 0.7326\n",
            "Epoch 373/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.5012 - accuracy: 0.7331\n",
            "Epoch 374/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.5007 - accuracy: 0.7345\n",
            "Epoch 375/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.5011 - accuracy: 0.7328\n",
            "Epoch 376/500\n",
            "21483/21483 [==============================] - 40s 2ms/step - loss: 0.5011 - accuracy: 0.7341\n",
            "Epoch 377/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.5008 - accuracy: 0.7338\n",
            "Epoch 378/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.5006 - accuracy: 0.7338\n",
            "Epoch 379/500\n",
            "21483/21483 [==============================] - 40s 2ms/step - loss: 0.5005 - accuracy: 0.7343\n",
            "Epoch 380/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.5008 - accuracy: 0.7324\n",
            "Epoch 381/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.5008 - accuracy: 0.7339\n",
            "Epoch 382/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.5007 - accuracy: 0.7336\n",
            "Epoch 383/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.5006 - accuracy: 0.7345\n",
            "Epoch 384/500\n",
            "21483/21483 [==============================] - 40s 2ms/step - loss: 0.5006 - accuracy: 0.7335\n",
            "Epoch 385/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.5008 - accuracy: 0.7347\n",
            "Epoch 386/500\n",
            "21483/21483 [==============================] - 40s 2ms/step - loss: 0.5003 - accuracy: 0.7342\n",
            "Epoch 387/500\n",
            "21483/21483 [==============================] - 40s 2ms/step - loss: 0.5006 - accuracy: 0.7356\n",
            "Epoch 388/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.5005 - accuracy: 0.7350\n",
            "Epoch 389/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.5004 - accuracy: 0.7336\n",
            "Epoch 390/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.5004 - accuracy: 0.7338\n",
            "Epoch 391/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.5000 - accuracy: 0.7346\n",
            "Epoch 392/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.5000 - accuracy: 0.7336\n",
            "Epoch 393/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4997 - accuracy: 0.7345\n",
            "Epoch 394/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.5000 - accuracy: 0.7338\n",
            "Epoch 395/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.5000 - accuracy: 0.7350\n",
            "Epoch 396/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4997 - accuracy: 0.7335\n",
            "Epoch 397/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.5000 - accuracy: 0.7340\n",
            "Epoch 398/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4994 - accuracy: 0.7345\n",
            "Epoch 399/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4993 - accuracy: 0.7335\n",
            "Epoch 400/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4998 - accuracy: 0.7354\n",
            "Epoch 401/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4993 - accuracy: 0.7329\n",
            "Epoch 402/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4994 - accuracy: 0.7345\n",
            "Epoch 403/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4992 - accuracy: 0.7360\n",
            "Epoch 404/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4990 - accuracy: 0.7346\n",
            "Epoch 405/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4992 - accuracy: 0.7350\n",
            "Epoch 406/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4990 - accuracy: 0.7345\n",
            "Epoch 407/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4994 - accuracy: 0.7344\n",
            "Epoch 408/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4992 - accuracy: 0.7348\n",
            "Epoch 409/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4989 - accuracy: 0.7340\n",
            "Epoch 410/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4987 - accuracy: 0.7352\n",
            "Epoch 411/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4986 - accuracy: 0.7346\n",
            "Epoch 412/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4984 - accuracy: 0.7363\n",
            "Epoch 413/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4985 - accuracy: 0.7343\n",
            "Epoch 414/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4983 - accuracy: 0.7342\n",
            "Epoch 415/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4986 - accuracy: 0.7351\n",
            "Epoch 416/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4981 - accuracy: 0.7342\n",
            "Epoch 417/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4981 - accuracy: 0.7364\n",
            "Epoch 418/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4983 - accuracy: 0.7352\n",
            "Epoch 419/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4980 - accuracy: 0.7350\n",
            "Epoch 420/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4981 - accuracy: 0.7336\n",
            "Epoch 421/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4977 - accuracy: 0.7343\n",
            "Epoch 422/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4974 - accuracy: 0.7373\n",
            "Epoch 423/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4978 - accuracy: 0.7357\n",
            "Epoch 424/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4973 - accuracy: 0.7360\n",
            "Epoch 425/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4977 - accuracy: 0.7350\n",
            "Epoch 426/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4977 - accuracy: 0.7350\n",
            "Epoch 427/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4973 - accuracy: 0.7352\n",
            "Epoch 428/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4975 - accuracy: 0.7357\n",
            "Epoch 429/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4970 - accuracy: 0.7360\n",
            "Epoch 430/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4969 - accuracy: 0.7365\n",
            "Epoch 431/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4968 - accuracy: 0.7365\n",
            "Epoch 432/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4969 - accuracy: 0.7357\n",
            "Epoch 433/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4967 - accuracy: 0.7355\n",
            "Epoch 434/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4967 - accuracy: 0.7360\n",
            "Epoch 435/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4965 - accuracy: 0.7363\n",
            "Epoch 436/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4963 - accuracy: 0.7341\n",
            "Epoch 437/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4962 - accuracy: 0.7354\n",
            "Epoch 438/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4960 - accuracy: 0.7359\n",
            "Epoch 439/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4959 - accuracy: 0.7351\n",
            "Epoch 440/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4954 - accuracy: 0.7367\n",
            "Epoch 441/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4952 - accuracy: 0.7367\n",
            "Epoch 442/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4953 - accuracy: 0.7356\n",
            "Epoch 443/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4953 - accuracy: 0.7350\n",
            "Epoch 444/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4949 - accuracy: 0.7347\n",
            "Epoch 445/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4953 - accuracy: 0.7358\n",
            "Epoch 446/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4952 - accuracy: 0.7367\n",
            "Epoch 447/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4952 - accuracy: 0.7357\n",
            "Epoch 448/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4947 - accuracy: 0.7362\n",
            "Epoch 449/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4946 - accuracy: 0.7358\n",
            "Epoch 450/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4945 - accuracy: 0.7361\n",
            "Epoch 451/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4945 - accuracy: 0.7347\n",
            "Epoch 452/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4941 - accuracy: 0.7357\n",
            "Epoch 453/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4943 - accuracy: 0.7346\n",
            "Epoch 454/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4940 - accuracy: 0.7378\n",
            "Epoch 455/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4940 - accuracy: 0.7349\n",
            "Epoch 456/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4938 - accuracy: 0.7359\n",
            "Epoch 457/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4935 - accuracy: 0.7367\n",
            "Epoch 458/500\n",
            "21483/21483 [==============================] - 42s 2ms/step - loss: 0.4937 - accuracy: 0.7363\n",
            "Epoch 459/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4932 - accuracy: 0.7365\n",
            "Epoch 460/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4935 - accuracy: 0.7356\n",
            "Epoch 461/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4932 - accuracy: 0.7357\n",
            "Epoch 462/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4929 - accuracy: 0.7370\n",
            "Epoch 463/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4934 - accuracy: 0.7365\n",
            "Epoch 464/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4928 - accuracy: 0.7365\n",
            "Epoch 465/500\n",
            "21483/21483 [==============================] - 42s 2ms/step - loss: 0.4931 - accuracy: 0.7375\n",
            "Epoch 466/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4929 - accuracy: 0.7372\n",
            "Epoch 467/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4924 - accuracy: 0.7363\n",
            "Epoch 468/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4927 - accuracy: 0.7384\n",
            "Epoch 469/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4926 - accuracy: 0.7382\n",
            "Epoch 470/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4922 - accuracy: 0.7402\n",
            "Epoch 471/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4919 - accuracy: 0.7385\n",
            "Epoch 472/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4919 - accuracy: 0.7371\n",
            "Epoch 473/500\n",
            "21483/21483 [==============================] - 42s 2ms/step - loss: 0.4919 - accuracy: 0.7377\n",
            "Epoch 474/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4917 - accuracy: 0.7375\n",
            "Epoch 475/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4915 - accuracy: 0.7399\n",
            "Epoch 476/500\n",
            "21483/21483 [==============================] - 42s 2ms/step - loss: 0.4916 - accuracy: 0.7387\n",
            "Epoch 477/500\n",
            "21483/21483 [==============================] - 42s 2ms/step - loss: 0.4913 - accuracy: 0.7380\n",
            "Epoch 478/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4912 - accuracy: 0.7391\n",
            "Epoch 479/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4915 - accuracy: 0.7383\n",
            "Epoch 480/500\n",
            "21483/21483 [==============================] - 42s 2ms/step - loss: 0.4909 - accuracy: 0.7390\n",
            "Epoch 481/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4910 - accuracy: 0.7389\n",
            "Epoch 482/500\n",
            "21483/21483 [==============================] - 42s 2ms/step - loss: 0.4911 - accuracy: 0.7384\n",
            "Epoch 483/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4906 - accuracy: 0.7384\n",
            "Epoch 484/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4911 - accuracy: 0.7381\n",
            "Epoch 485/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4907 - accuracy: 0.7374\n",
            "Epoch 486/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4908 - accuracy: 0.7396\n",
            "Epoch 487/500\n",
            "21483/21483 [==============================] - 42s 2ms/step - loss: 0.4905 - accuracy: 0.7393\n",
            "Epoch 488/500\n",
            "21483/21483 [==============================] - 42s 2ms/step - loss: 0.4904 - accuracy: 0.7372\n",
            "Epoch 489/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4902 - accuracy: 0.7404\n",
            "Epoch 490/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4903 - accuracy: 0.7405\n",
            "Epoch 491/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4898 - accuracy: 0.7383\n",
            "Epoch 492/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4897 - accuracy: 0.7408\n",
            "Epoch 493/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4903 - accuracy: 0.7398\n",
            "Epoch 494/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4895 - accuracy: 0.7408\n",
            "Epoch 495/500\n",
            "21483/21483 [==============================] - 42s 2ms/step - loss: 0.4897 - accuracy: 0.7395\n",
            "Epoch 496/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4896 - accuracy: 0.7390\n",
            "Epoch 497/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4895 - accuracy: 0.7395\n",
            "Epoch 498/500\n",
            "21483/21483 [==============================] - 42s 2ms/step - loss: 0.4895 - accuracy: 0.7402\n",
            "Epoch 499/500\n",
            "21483/21483 [==============================] - 42s 2ms/step - loss: 0.4894 - accuracy: 0.7407\n",
            "Epoch 500/500\n",
            "21483/21483 [==============================] - 41s 2ms/step - loss: 0.4893 - accuracy: 0.7403\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "id": "obeaFp487Aqd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a21a8551-0c8d-4266-a144-02319ed9e781"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "288/288 [==============================] - 1s 2ms/step - loss: 0.4887 - accuracy: 0.7384\n",
            "Test loss: 0.4886535704135895\n",
            "Test accuracy: 0.7383796572685242\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test[0])\n",
        "prediction = model.predict(X_test[0].reshape(1,9))\n",
        "print(\"Prediction class:\",np.round(prediction[0]))\n",
        "print(\"Actual class:\",y_test[0])"
      ],
      "metadata": {
        "id": "GnwizKkB7kYk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05f9dfb8-249e-48f9-b1bc-fe8e674250d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.43023256 0.0080429  0.00510204 0.06155349 0.02110553 0.00426916\n",
            " 0.76811594 0.84782609 0.48      ]\n",
            "Prediction class: [1.]\n",
            "Actual class: [0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot( acc, label='Training Accuracy')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training  Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot( loss, label='Training Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Test Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hpS2Skhfcrzu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "88854533-2e86-49ee-d3e9-56627519df31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction=model.predict(X_test)\n",
        "pred = []\n",
        "for i in prediction:\n",
        "  if(i < 0.299):\n",
        "    pred.append([0])\n",
        "  else:\n",
        "    pred.append([1])\n",
        "confusion_matrix(y_test,pred)"
      ],
      "metadata": {
        "id": "SnkmQPQcvEhl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d78ad7b-ff64-4af7-d4bd-69f5510ac357"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3891, 2682],\n",
              "       [ 418, 2217]])"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"Binary_Model.h5\")"
      ],
      "metadata": {
        "id": "OylDCWjfEt5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_columns = data1.columns\n",
        "input_data=pd.DataFrame(columns=list_of_columns)\n",
        "input_data.drop(['Result'], axis='columns', inplace=True)\n",
        "\n",
        "input_data.at[0, 'Age of the patient'] = int(input('enter age of the patient'))\n",
        "input_data.at[0, 'Total Bilirubin'] = float(input('enter value of total bilirubin in blood'))\n",
        "input_data.at[0, 'Direct Bilirubin'] = float(input('enter value of direct bilirubin in blood'))\n",
        "input_data.at[0, '\\xa0Alkphos Alkaline Phosphotase'] = int(input('enter value of alkphos alkaline in blood'))\n",
        "input_data.at[0, '\\xa0Sgpt Alamine Aminotransferase'] = int(input('enter value of sgpt alamine in blood'))\n",
        "input_data.at[0, 'Sgot Aspartate Aminotransferase'] = int(input('enter value of sgot asparatate in blood'))\n",
        "input_data.at[0, 'Total Protiens'] = float(input('enter value of total protiens in blood'))\n",
        "input_data.at[0, '\\xa0ALB Albumin'] = float(input('enter alb albumin in blood'))\n",
        "input_data.at[0, 'A/G Ratio Albumin and Globulin Ratio'] = float(input('enter value of a/g ratio albumin and globulin ratio'))\n",
        "input_data['Age of the patient']=(input_data['Age of the patient']-data1['Age of the patient'].min())/(data1['Age of the patient'].max()-data1['Age of the patient'].min())\n",
        "input_data['Total Bilirubin']=(input_data['Total Bilirubin']-data1['Total Bilirubin'].min())/(data1['Total Bilirubin'].max()-data1['Total Bilirubin'].min())\n",
        "input_data['Direct Bilirubin']=(input_data['Direct Bilirubin']-data1['Direct Bilirubin'].min())/(data1['Direct Bilirubin'].max()-data1['Direct Bilirubin'].min())\n",
        "input_data['\\xa0Alkphos Alkaline Phosphotase']=(input_data['\\xa0Alkphos Alkaline Phosphotase']-data1['\\xa0Alkphos Alkaline Phosphotase'].min())/(data1['\\xa0Alkphos Alkaline Phosphotase'].max()-data1['\\xa0Alkphos Alkaline Phosphotase'].min())\n",
        "input_data['\\xa0Sgpt Alamine Aminotransferase']=(input_data['\\xa0Sgpt Alamine Aminotransferase']-data1['\\xa0Sgpt Alamine Aminotransferase'].min())/(data1['\\xa0Sgpt Alamine Aminotransferase'].max()-data1['\\xa0Sgpt Alamine Aminotransferase'].min())\n",
        "input_data['Total Protiens']=(input_data['Total Protiens']-data1['Total Protiens'].min())/(data1['Total Protiens'].max()-data1['Total Protiens'].min())\n",
        "input_data['\\xa0ALB Albumin']=(input_data['\\xa0ALB Albumin']-data1['\\xa0ALB Albumin'].min())/(data1['\\xa0ALB Albumin'].max()-data1['\\xa0ALB Albumin'].min())\n",
        "input_data['A/G Ratio Albumin and Globulin Ratio']=(input_data['A/G Ratio Albumin and Globulin Ratio']-data1['A/G Ratio Albumin and Globulin Ratio'].min())/(data1['A/G Ratio Albumin and Globulin Ratio'].max()-data1['A/G Ratio Albumin and Globulin Ratio'].min())\n",
        "#n = np.asarray(input_data).astype(np.float32)\n",
        "from keras.models import load_model\n",
        "model = load_model('Binary_Model.h5')\n",
        "n = np.asarray(input_data).astype(np.float32)\n",
        "prediction = model.predict(n[0].reshape(1,9))\n",
        "result = prediction[0]\n",
        "#predict=result*(data1['Result'].max()-data1['Result'].min())+data1['Result'].min()\n",
        "predict1=np.round(result)\n",
        "print('result',predict1)\n",
        "if predict1==1:\n",
        "  print('having  liver cancer disease')\n",
        "else:\n",
        "  print('not having liver cancer disease')\n"
      ],
      "metadata": {
        "id": "f4g3WeRcFDmd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}